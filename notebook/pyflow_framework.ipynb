{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyflow framework.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "onDNUbeowtbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f3d0678-959e-4caf-c7cc-7fb4ec24327e"
      },
      "source": [
        "!pip install texttable\r\n",
        "# Helper libraries\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import gzip\r\n",
        "from PIL import Image\r\n",
        "import cv2\r\n",
        "import os\r\n",
        "import pickle\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import requests\r\n",
        "import pandas as pd\r\n",
        "from texttable import Texttable\r\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting texttable\n",
            "  Downloading https://files.pythonhosted.org/packages/06/f5/46201c428aebe0eecfa83df66bf3e6caa29659dbac5a56ddfd83cae0d4a4/texttable-1.6.3-py2.py3-none-any.whl\n",
            "Installing collected packages: texttable\n",
            "Successfully installed texttable-1.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0_KdWpIevoy"
      },
      "source": [
        "class Visualizer():\r\n",
        "    '''\r\n",
        "    Class encapsulates the visualization method that plots the loss and required evaluation metrics against the epoch number.\r\n",
        "    Attributes:\r\n",
        "        losses: List of calculated scaler losses occured at each epoch.\r\n",
        "        accuracy: List of calculated scaler accuracies occured at each epoch.\r\n",
        "        f1score: List of calculated scaler f1scores occured at each epoch.\r\n",
        "        precision: List of calculated scaler precisions occured at each epoch.\r\n",
        "        recall: List of calculated scaler recalls occured at each epoch. \r\n",
        "        mode: String represents the metric required to be visualized.\r\n",
        "        metric_mode: List of metric values according to the passed mode.\r\n",
        "    '''\r\n",
        "    # This function is called when the training begins\r\n",
        "    def __init__(self, mode= 'all'):\r\n",
        "        '''\r\n",
        "        Initializes the class attributes.\r\n",
        "        '''\r\n",
        "        # Initialize the lists for holding the logs, losses and metrics\r\n",
        "        self.losses = []\r\n",
        "        self.accuracy = []\r\n",
        "        self.f1score = []\r\n",
        "        self.precision = []\r\n",
        "        self.recall = []\r\n",
        "        self.mode = mode\r\n",
        "        self.metric_mode = []\r\n",
        "\r\n",
        "\r\n",
        "    # This function is called at the end of each epoch\r\n",
        "    def on_epoch_end(self, logs={}):\r\n",
        "        \"\"\"\r\n",
        "        Calculates and plots Precision, Recall, F1 score\r\n",
        "        Arguments:\r\n",
        "            logs: Dictionary consists of the metric mode name as dictionary key and its values as dictionary values. The dictionary also have special entry for the loss with the string \"loss\" as dictionary entry key and the value of the loss at the given epoch as dictionary entry value.\r\n",
        "        \"\"\"\r\n",
        "        # Extract from the log\r\n",
        "        if self.mode == \"all\":\r\n",
        "            accuracy = logs['accuracy']\r\n",
        "            f1score =logs['f1']\r\n",
        "            recall =logs['recall']\r\n",
        "            precision =logs['precision']\r\n",
        "            self.accuracy.append(accuracy)\r\n",
        "            self.f1score.append(f1score)\r\n",
        "            self.precision.append(precision)\r\n",
        "            self.recall.append(recall)\r\n",
        "        else:\r\n",
        "            metric_mode = logs[self.mode]\r\n",
        "            self.metric_mode.append(metric_mode)\r\n",
        "        loss=logs['loss']\r\n",
        "        self.losses.append(loss)\r\n",
        "    \r\n",
        "        # Clear the previous plot\r\n",
        "        if logs['type']==\"train\":\r\n",
        "          clear_output(wait=True)\r\n",
        "        N = np.arange(1, len(self.losses)+1)\r\n",
        "        \r\n",
        "        # You can chose the style of your preference\r\n",
        "\r\n",
        "        plt.style.use(\"seaborn\")\r\n",
        "        plt.figure(figsize=(20,4))\r\n",
        "        # Plot train loss, train acc, val loss and val acc against epochs passed\r\n",
        "        plt.title(\"{} Loss over epoch number {}\".format(logs['type'],len(self.losses)))\r\n",
        "        plt.ylabel(\"Loss\")\r\n",
        "        plt.plot(N, self.losses,c='blue', marker='o', linestyle='solid')\r\n",
        "\r\n",
        "\r\n",
        "        if (self.mode == \"all\"):\r\n",
        "            fig, ax = plt.subplots(1,4, figsize=(20,4))\r\n",
        "            ax = ax.ravel()\r\n",
        "            ax[0].plot(N, self.precision, label = \"Precision\", c = 'red', marker='o', linestyle='solid')\r\n",
        "            ax[1].plot(N, self.recall, label = \"Recall\", c = 'red', marker='o', linestyle='solid')\r\n",
        "            ax[2].plot(N, self.f1score, label = \"F1 score\", c = 'red', marker='o', linestyle='solid')\r\n",
        "            ax[3].plot(N, self.accuracy, label = \"Precision\", c = 'red', marker='o', linestyle='solid')\r\n",
        "            ax[0].set_title(\"Precision at Epoch No. {}\".format(len(self.losses)))\r\n",
        "            ax[1].set_title(\"Recall at Epoch No. {}\".format(len(self.losses)))\r\n",
        "            ax[2].set_title(\"F1-score at Epoch No. {}\".format(len(self.losses)))\r\n",
        "            ax[3].set_title(\"Accuracy at Epoch No. {}\".format(len(self.losses)))\r\n",
        "            ax[0].set_xlabel(\"Epoch #\")\r\n",
        "            ax[1].set_xlabel(\"Epoch #\")\r\n",
        "            ax[2].set_xlabel(\"Epoch #\")\r\n",
        "            ax[3].set_xlabel(\"Epoch #\")\r\n",
        "            ax[0].set_ylabel(\"Precision\")\r\n",
        "            ax[1].set_ylabel(\"Recall\")\r\n",
        "            ax[2].set_ylabel(\"F1 score\")\r\n",
        "            ax[3].set_ylabel(\"Accuracy\")\r\n",
        "            ax[0].set_ylim(0,1)\r\n",
        "            ax[1].set_ylim(0,1)\r\n",
        "            ax[2].set_ylim(0,1)\r\n",
        "            ax[3].set_ylim(0,1)\r\n",
        "        else:\r\n",
        "            fig, ax = plt.subplots(1,1, figsize=(12,4))\r\n",
        "            ax.plot(N, self.metric_mode, label = self.mode, c = 'red', marker='o', linestyle='solid')\r\n",
        "            ax.set_title(\"{} at Epoch No. {}\".format(self.mode, len(self.losses)))\r\n",
        "            ax.set_xlabel(\"Epoch #\")\r\n",
        "            ax.set_ylabel(self.mode)\r\n",
        "            ax.set_ylim(0,1)\r\n",
        "        plt.show()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmrjDG20gQ5o"
      },
      "source": [
        "'''\r\n",
        "First: Some Utilities\r\n",
        "The following three functions are used to dowload the dataset if it is not available in the path specified when instantiating an object of the dataset class.\r\n",
        "We uploaded the dataset files to google drive to be easily accessed from remote computers.\r\n",
        "These fuctions were taken from a stackoverflow answer.\r\n",
        "Generally, one call of download_file_from_google_drive downloads one file.\r\n",
        "The following three functions is not part of the framework so they will not be documented.  \r\n",
        "'''\r\n",
        "def download_file_from_google_drive(id, destination, status):\r\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\r\n",
        "\r\n",
        "    session = requests.Session()\r\n",
        "\r\n",
        "    response = session.get(URL, params = { 'id': id }, stream = True)\r\n",
        "    token = get_confirm_token(response)\r\n",
        "\r\n",
        "    print(f'Downloading {status}...')\r\n",
        "    if token:\r\n",
        "        params = { 'id': id, 'confirm': token }\r\n",
        "        response = session.get(URL, params = params, stream = True)\r\n",
        "    save_response_content(response, destination)    \r\n",
        "    print(\"Finished Successfully.\")\r\n",
        "\r\n",
        "def get_confirm_token(response):\r\n",
        "    for key, value in response.cookies.items():\r\n",
        "        if key.startswith('download_warning'):\r\n",
        "            return value\r\n",
        "    return None\r\n",
        "\r\n",
        "def save_response_content(response, destination):\r\n",
        "    CHUNK_SIZE = 32768\r\n",
        "\r\n",
        "    with open(destination, \"wb\") as f:\r\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\r\n",
        "            if chunk: # filter out keep-alive new chunks\r\n",
        "                f.write(chunk)\r\n",
        "\r\n",
        "class Dataset():\r\n",
        "    '''\r\n",
        "    Abstract class represents a dataset. Generally, any dataset inherits from this class have to have path to the root file which contains all its files.\r\n",
        "    Methods:\r\n",
        "        __getItem__() simply returns an item of the dataset. An item is the combination of an image and its corresponding label. The item maybe training, validation or test item.\r\n",
        "        length() gets the length of a certain (training, validation or test) subset of the dataset.\r\n",
        "        load() returns the training, validation and test sets splitted in arrays. \r\n",
        "    '''\r\n",
        "    def __init__(self, rootFilePath):\r\n",
        "        self.rootFilePath = rootFilePath\r\n",
        "    def __getItem__(self, index):\r\n",
        "        raise NotImplementedError\r\n",
        "    def length(self):\r\n",
        "        raise NotImplementedError\r\n",
        "    def load(self):\r\n",
        "        raise NotImplementedError\r\n",
        "\r\n",
        "class Mnist(Dataset):\r\n",
        "    '''\r\n",
        "    Class representing the Mnist \"iterable\" dataset. \r\n",
        "    The class stores the google drive file Id of each of the mnist dataset files. These Ids are essential to download the files if they are not available in the specified root path.\r\n",
        "    It also stores the names of gzip files that contains the training and test sets. \r\n",
        "    \"Set\" here refers to the the combination of an image and a label.\r\n",
        "    The class stores the splitted training, validation and test sets in numpy arrays.\r\n",
        "    The class finally stores __index and iterate_on_attr attributes which used in iterating on the datasets\r\n",
        "    '''\r\n",
        "    trainingImagesId = '1AFEVsHzlT8H_avcouMl694PwFEyNzirr'\r\n",
        "    trainingLabelsId = '1rhFLe9WbSK8bnbXnglX9b4AgOB7tfPsS'\r\n",
        "    testImagesId = '1duWaOCrpieH9O9GKMR-xIUSzRJNFyVOQ'\r\n",
        "    testLabelsId = '1IEhyDpgPgKv-S6Sx7AIufUmjmH97Om6w'\r\n",
        "    def __init__(self, rootFilePath, seed = 42, split_ratio = 0.2): \r\n",
        "        '''\r\n",
        "        The __init__ function is called whenever the class is instantiated. \r\n",
        "        Arguments: \r\n",
        "            rootFilePath: String represents the path to the root folder in which the dataset files are stored. If the files were not found, the object notifies the user that it will procceed downloading the dataset files online from the internet.\r\n",
        "            seed: Integer represents the seed of the random process of numpy. numpy.random is used to randomly shuffle the training set. The user can set the seed of the random shuffling to match a constant seed he/she wants across the code.\r\n",
        "            split_ratio: float represents the ratio by which the mnist training files are split into validation and training sets. The split_ratio equals the required portion of validation set of the total given mnist training set. If the user needs to do the split manually, the he/she can set the split_ratio to zero and the object stores only training and test sets.\r\n",
        "        '''\r\n",
        "        super(Mnist, self).__init__(rootFilePath)\r\n",
        "        self.trainingImagesName = os.path.join(self.rootFilePath, 'train-images-idx3-ubyte.gz')\r\n",
        "        self.trainingLabelsName = os.path.join(self.rootFilePath, 'train-labels-idx1-ubyte.gz')\r\n",
        "        self.testImagesName = os.path.join(self.rootFilePath, 't10k-images-idx3-ubyte.gz')\r\n",
        "        self.testLabelsName = os.path.join(self.rootFilePath, 't10k-labels-idx1-ubyte.gz')\r\n",
        "        if not os.path.exists(self.trainingImagesName)\\\r\n",
        "           or not os.path.exists(self.trainingLabelsName)\\\r\n",
        "           or not os.path.exists(self.testImagesName)\\\r\n",
        "           or not os.path.exists(self.testLabelsName):\r\n",
        "           response = input('Some files are missing. Do you want to download the dataset online? [y/n]')\r\n",
        "           if response.lower() == \"n\":\r\n",
        "               raise SystemExit()\r\n",
        "           else:\r\n",
        "               download_file_from_google_drive(self.trainingImagesId, self.trainingImagesName, \"Training Images\")\r\n",
        "               download_file_from_google_drive(self.trainingLabelsId, self.trainingLabelsName, \"Training Labels\")\r\n",
        "               download_file_from_google_drive(self.testImagesId, self.testImagesName, \"Test Images\")\r\n",
        "               download_file_from_google_drive(self.testLabelsId, self.testLabelsName, \"Test Labels\")\r\n",
        "        training_and_validation_images = self.get_images(self.trainingImagesName).copy()\r\n",
        "        training_and_validation_labels = self.get_labels(self.trainingLabelsName).copy()\r\n",
        "        np.random.seed(seed)\r\n",
        "        state = np.random.get_state()\r\n",
        "        np.random.shuffle(training_and_validation_images)\r\n",
        "        np.random.set_state(state)\r\n",
        "        np.random.shuffle(training_and_validation_labels)\r\n",
        "        training_end_index = int((1 - split_ratio)*len(training_and_validation_images))\r\n",
        "        self.training_images = training_and_validation_images[:training_end_index]\r\n",
        "        self.training_labels = training_and_validation_labels[:training_end_index]\r\n",
        "        self.validation_images = training_and_validation_images[training_end_index:]\r\n",
        "        self.validation_labels = training_and_validation_labels[training_end_index:]\r\n",
        "        self.test_images = self.get_images(self.testImagesName)\r\n",
        "        self.test_labels = self.get_labels(self.testLabelsName)\r\n",
        "        self.__index = 0\r\n",
        "        self.iterate_on_attr = \"training\"\r\n",
        "    def iterate_on(self, iterate_on):\r\n",
        "        '''\r\n",
        "        Specifies which set (training, validation or test) is to be iterated on.\r\n",
        "        Arguments:\r\n",
        "            iterate_on: string indicates the set to be iterated on.\r\n",
        "        '''\r\n",
        "        self.iterate_on_attr = iterate_on\r\n",
        "    def load(self):\r\n",
        "        '''\r\n",
        "        Returns:\r\n",
        "            training_images: array of shape (<num_of_training_imgs>, 28, 28) contains training images, each of 28x28 shape.\r\n",
        "            training_labels: array of shape (<num_of_training_imgs>, 1) contains the labels corresponding to the training images.\r\n",
        "            validation_images: array of shape (<num_of_validation_imgs>, 28, 28) contains validation images, each of 28x28 shape.\r\n",
        "            validation_labels: array of shape (<num_of_validation_imgs>, 1) contains the labels corresponding to the validation images.\r\n",
        "            test_images: array of shape (10000, 28, 28) contains test images, each of 28x28 shape.\r\n",
        "            test_labels: array of shape (10000, 1) contains the labels corresponding to the test images.\r\n",
        "        '''\r\n",
        "        return self.training_images, self.training_labels, self.validation_images, self.validation_labels, self.test_images, self.test_labels\r\n",
        "    def __getItem__(self, index, from_set = \"training\", all = False):\r\n",
        "        '''\r\n",
        "        Gets an item of a specific set at a specific index.\r\n",
        "        Arguments:\r\n",
        "            index: Integer represents the index of the specified set from which an item (image + label) is gotten.\r\n",
        "            from_set: String represents the set from which the item (image + label) is gotten.\r\n",
        "            all: Boolean that if set true, the function returns a specific item the is combined of one training image, one training label, one validation image, one validation label, one test image and one test label.\r\n",
        "        Returns:\r\n",
        "            PILImage: Python Imaging Library (PIL) image from an array at the given index from the given set.\r\n",
        "            intLabels: Integer represents the label that corresponds to the returned PIL Image.\r\n",
        "        '''\r\n",
        "        from_set = from_set.lower()\r\n",
        "        if from_set == \"training\" and not all:\r\n",
        "            PILImage = Image.fromarray(self.training_images[index], mode= 'L') \r\n",
        "            # mode = 'L' indicates 8 bits black and white images\r\n",
        "            intLabels = self.training_labels[index].item()\r\n",
        "        elif from_set == \"test\" and not all:\r\n",
        "            PILImage = Image.fromarray(self.test_images[index], mode= 'L') \r\n",
        "            intLabels = self.test_labels[index].item()\r\n",
        "        elif from_set == \"validation\" and not all:\r\n",
        "            PILImage = Image.fromarray(self.validation_images[index], mode= 'L') \r\n",
        "            intLabels = self.validation_labels[index].item()\r\n",
        "        elif all:\r\n",
        "            return Image.fromarray(self.training_images[index], mode= 'L'),\\\r\n",
        "            self.training_labels[index].item(),\\\r\n",
        "            Image.fromarray(self.validation_images[index], mode= 'L'),\\\r\n",
        "            self.validation_labels[index].item(),\\\r\n",
        "            Image.fromarray(self.test_images[index], mode= 'L'),\\\r\n",
        "            self.test_labels[index].item()\r\n",
        "        return PILImage, intLabels\r\n",
        "    def length(self, set = \"training\"):\r\n",
        "        '''\r\n",
        "        Gets the length of a specified set.\r\n",
        "        Arguments:\r\n",
        "            set: String represents the set which its length is required.\r\n",
        "        Returns:\r\n",
        "            The length of the specified set.\r\n",
        "        '''\r\n",
        "        set = set.lower()\r\n",
        "        if set == \"training\":\r\n",
        "            return len(self.training_images)\r\n",
        "        elif set == \"test\":\r\n",
        "            return len(self.test_images)\r\n",
        "        elif set == \"validation\":\r\n",
        "            return len(self.validation_images)\r\n",
        "    def __iter__(self):\r\n",
        "        '''\r\n",
        "        The function required to make the dataset iterable.\r\n",
        "        '''\r\n",
        "        self.__index = 0\r\n",
        "        return self \r\n",
        "    def __next__(self):\r\n",
        "        '''\r\n",
        "        The function that gets the next item from the iterable.\r\n",
        "        Returns:\r\n",
        "            The next item from the set specified by the iterate_on_attr.\r\n",
        "        '''\r\n",
        "        if self.__index < self.length(self.iterate_on_attr):\r\n",
        "            next = self.__getItem__(self.__index, from_set = self.iterate_on_attr)\r\n",
        "            self.__index += 1\r\n",
        "            return next\r\n",
        "        else:\r\n",
        "            raise StopIteration\r\n",
        "    def generate(self, from_set = \"training\", index= 0):\r\n",
        "        '''\r\n",
        "        Generator function that continously generates items from the specifed set starting from a given index.\r\n",
        "        Arguments:\r\n",
        "            from_set: String indicates the set that items are being generated from.\r\n",
        "            index: Integer indicates the place from which the function starts the generation.\r\n",
        "        Yields (Actually it returns continously):\r\n",
        "            An item of the given set at the given item. \r\n",
        "        '''\r\n",
        "        internal_index = index\r\n",
        "        while True:\r\n",
        "            if internal_index < self.length(from_set):\r\n",
        "                yield self.__getItem__(internal_index, from_set = from_set)\r\n",
        "                internal_index += 1\r\n",
        "            else: \r\n",
        "                break\r\n",
        "    def showSample(self, from_set = \"training\", startFrom= 0, coloumn= 5, row= 5, figsize= (10, 10)):\r\n",
        "        '''\r\n",
        "        Plots a sample of images and labels from a given set.\r\n",
        "        Arguments:\r\n",
        "            from_set: String indicates the set that the shown sample is from.\r\n",
        "            startFrom: Integer indicates the index from which the function will visualize a set of images.\r\n",
        "            coloumn: Integer indicates number of coloumns of images is required. \r\n",
        "            row: Integer indicates number of rows of images is required. \r\n",
        "            figsize: Tuple of two integers indicates the area of an image (passed to matplotlib.pyplot.plot).\r\n",
        "        '''\r\n",
        "        from_set = from_set.lower()\r\n",
        "        fig = plt.figure(figsize= figsize)\r\n",
        "        mnist_iter = self.generate(from_set, startFrom)\r\n",
        "        for i in range(1, coloumn*row+1):\r\n",
        "            img, label = next(mnist_iter)\r\n",
        "            ax = fig.add_subplot(row, coloumn, i)\r\n",
        "            ax.title.set_text('Label: ' + str(label))\r\n",
        "            plt.imshow(img)\r\n",
        "            plt.axis('off')\r\n",
        "        plt.show()\r\n",
        "    def read_idx_file(self, f, num_bytes= 4, endianness= 'big'):\r\n",
        "        '''\r\n",
        "        Reads specific number of bytes from a given .idx file (used to store the mnist dataset) taking endianness into consideration.\r\n",
        "        Arguments:\r\n",
        "            f: .idx (index) file.\r\n",
        "            num_bytes: Integer number of bytes to be read from the given .idx file.\r\n",
        "            endianness: String specifies the endianness of the given file. (C.O. Lesson: Endianness-> The way computer stores the bytes in memory. Big endian processor stores the most significant byte in the highest memory address and vice versa)\r\n",
        "        Returns:\r\n",
        "            Series of integers from the read bytes.\r\n",
        "        '''\r\n",
        "        return int.from_bytes(f.read(num_bytes), endianness)\r\n",
        "    def get_images(self, compressedFilePath):\r\n",
        "        '''\r\n",
        "        Transforms the raw bytes read from the idx file into images.\r\n",
        "        Arguments:\r\n",
        "            compressedFilePath: String represents the path of the compressed gzip file.\r\n",
        "        Returns:\r\n",
        "            images: Array of integers ranging from 0 to 255 representing the images in the given file.\r\n",
        "        '''\r\n",
        "        with gzip.open(compressedFilePath, 'r') as f:\r\n",
        "            magicNumber = self.read_idx_file(f) # Used to make sure that the file is read correctly.\r\n",
        "            try:\r\n",
        "                assert magicNumber == 2051 \r\n",
        "            except:\r\n",
        "                print('Error getting images (Magic number error)')\r\n",
        "                raise SystemExit()\r\n",
        "            num_images = self.read_idx_file(f) \r\n",
        "            num_rows = self.read_idx_file(f)\r\n",
        "            num_coloumns = self.read_idx_file(f)\r\n",
        "            rest_values = f.read()\r\n",
        "            images = np.frombuffer(rest_values, dtype = np.uint8).reshape((num_images, num_rows, num_coloumns))\r\n",
        "            return images\r\n",
        "    def get_labels(self, compressedFilePath):\r\n",
        "        '''\r\n",
        "        Transforms the raw bytes read from the idx file into labels.\r\n",
        "        Arguments:\r\n",
        "            compressedFilePath: String represents the path of the compressed gzip file.\r\n",
        "        Returns:\r\n",
        "            labels: Array of integers ranging from 0 to 9 representing the labels corresponding to the images in the given file.\r\n",
        "        '''\r\n",
        "        with gzip.open(compressedFilePath, 'r') as f:\r\n",
        "            magicNumber = self.read_idx_file(f) # Used to make sure that the file is read correctly.\r\n",
        "            try:\r\n",
        "                assert magicNumber == 2049 \r\n",
        "            except:\r\n",
        "                print('Error in training labels (Magic number error)')\r\n",
        "                raise SystemExit()\r\n",
        "            num_labels = self.read_idx_file(f)\r\n",
        "            rest_values = f.read()\r\n",
        "            labels = np.frombuffer(rest_values, dtype = np.uint8).reshape((num_labels, 1))\r\n",
        "            return labels"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xojFTvlQhgLO"
      },
      "source": [
        "class Storage():\r\n",
        "    def __init__(self):\r\n",
        "        pass\r\n",
        "    def save_model(self, model, file_name, save_path):\r\n",
        "        '''\r\n",
        "        This method saves the passed model into the passed path with the passed name.\r\n",
        "        Attributes:\r\n",
        "            model: Object of type model representing the current state of the model you want to save.\r\n",
        "            file_name: Beautiful name of your choice for the file to be pickled. If you want to save many models, then every model MUST have a unique name. If an already exists file name passed, then the saved old model will be lost.\r\n",
        "            save_path: The file path you want to save your model in. \r\n",
        "        '''\r\n",
        "        file_path = os.path.join(save_path, file_name + \".pickle\")\r\n",
        "        if os.path.exists(file_path):\r\n",
        "            print(\"WARNING: There is another model with the same name. The old one will be lost.\")\r\n",
        "        pickled_file = open(file_path, \"wb\")\r\n",
        "        pickle.dump(model, pickled_file)\r\n",
        "        pickled_file.close()\r\n",
        "    def load_model(self, file_name, load_path):\r\n",
        "        '''\r\n",
        "        This method loads a model from the passed path with the passed name.\r\n",
        "        Attributes:\r\n",
        "            file_name: Name of the file you saved your model in. If there is not a .pickle file with the same name, the methods returns None.\r\n",
        "            save_path: The file path you want to load your model from.\r\n",
        "        '''\r\n",
        "        file_path = os.path.join(load_path, file_name + \".pickle\")\r\n",
        "        if not os.path.exists(file_path):\r\n",
        "            print(\"File not found\")\r\n",
        "            return None\r\n",
        "        unpickled_file = open(file_path, \"rb\")\r\n",
        "        model = pickle.load(unpickled_file)\r\n",
        "        unpickled_file.close()\r\n",
        "        return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45CkGHH5iKTu"
      },
      "source": [
        "class Evaluation_metrics():\r\n",
        "  '''\r\n",
        "  Class encapsulates the following training process evaluation metrics: accuracy, precision, recall and F1score.\r\n",
        "  Attributes:\r\n",
        "    evaluation_type: String represents the metric of evaluation.\r\n",
        "    numberOfClasses: Integer represents the number of the output classes.\r\n",
        "    plot: if one, the confusion matrix is visually plotted.\r\n",
        "  '''\r\n",
        "  def __init__(self, evaluation_type=\"accuracy\", numberOfClasses=9, plot=0):\r\n",
        "    '''\r\n",
        "    Sets the class attributes to the passed attributes.\r\n",
        "    '''\r\n",
        "    self.evaluation_type=evaluation_type\r\n",
        "    self.numberOfClasses=numberOfClasses\r\n",
        "    self.plot=plot\r\n",
        "\r\n",
        "  def calculate_matrix(self, predection, label):\r\n",
        "    '''\r\n",
        "    Calculates the metrics from given predictions and labels.\r\n",
        "    Arguments:\r\n",
        "      prediction: Array of model predections.\r\n",
        "      label: Array of true labels.\r\n",
        "    Returns:\r\n",
        "      precision: float representing the precision\r\n",
        "      recall: float representing the recall\r\n",
        "      F1: float representing the f1score (harmonic mean of precision and recall)\r\n",
        "    '''\r\n",
        "    epslion=0.000001\r\n",
        "    label_series=pd.Series(label)\r\n",
        "    predection_series=pd.Series( predection)\r\n",
        "    df_M =pd.crosstab( predection_series,label_series)\r\n",
        "    M=df_M.to_numpy()\r\n",
        "    rows_sum= M.sum(axis=1)\r\n",
        "    coulmns_sum=M.sum(axis=0)\r\n",
        "    M=M.diagonal()\r\n",
        "    precision=M/(rows_sum +epslion)  # what proportion of predicted positives is truly positive ?\r\n",
        "    recall=M/(coulmns_sum+epslion)   # what proportion of actual positives is correctly classified ?\r\n",
        "    F1=2*(precision*recall)/(precision+recall+epslion)\r\n",
        "    final_M={\"precision\":precision,\r\n",
        "                            \"recall\":recall,\r\n",
        "                            \"F1 Score\":F1\r\n",
        "                            }\r\n",
        "    df=pd.DataFrame(final_M, columns = ['precision', 'recall','F1 Score'])\r\n",
        "    precision=sum(precision)/len(precision)\r\n",
        "    recall=sum(recall)/len(recall)\r\n",
        "    F1=sum(F1)/len(F1)\r\n",
        "    return precision, recall, F1\r\n",
        "\r\n",
        "  def plot_confusion_matrix(self, df_confusion, title='Confusion matrix', cmap= plt.cm.gray_r):\r\n",
        "    '''\r\n",
        "    Plots the confusion matrix using matplotlib.\r\n",
        "    Arguments:\r\n",
        "      df_confusion: The confusion matrix.\r\n",
        "      title: String representing the title of the plot.\r\n",
        "      cmap: matplotlib Color map.\r\n",
        "    '''\r\n",
        "    plt.matshow(df_confusion, cmap=cmap) # imshow\r\n",
        "    #plt.title(title)\r\n",
        "    plt.colorbar()\r\n",
        "    tick_marks = np.arange(len(df_confusion.columns))\r\n",
        "    plt.xticks(tick_marks, df_confusion.columns, rotation=45)\r\n",
        "    plt.yticks(tick_marks, df_confusion.index)\r\n",
        "    #plt.tight_layout()\r\n",
        "    plt.ylabel(df_confusion.index.name)\r\n",
        "    plt.xlabel(df_confusion.columns.name)\r\n",
        "\r\n",
        "\r\n",
        "  def confusion_matrix(self, predection, label):\r\n",
        "    '''\r\n",
        "    Transfroms the labels and predictions into a confusion matrix and plots it.\r\n",
        "    Arguments:\r\n",
        "      prediction: Array of model predections.\r\n",
        "      label: Array of true labels.\r\n",
        "    '''\r\n",
        "    label_series=pd.Series(label,name=\"Actual\")\r\n",
        "    predection_series=pd.Series( predection,name=\"predectied\")\r\n",
        "    df_confusion = pd.crosstab( predection_series,label_series)\r\n",
        "    self.plot_confusion_matrix(df_confusion, title='Confusion matrix', cmap= plt.cm.gray_r)\r\n",
        "\r\n",
        "  def accuracy (self, predection, label):\r\n",
        "    '''\r\n",
        "    Calculates the accuracy of a given model predictions.\r\n",
        "    Arguments:\r\n",
        "      prediction: Array of model predections.\r\n",
        "      label: Array of true labels.\r\n",
        "    Returns:\r\n",
        "      accuracy: float represents the accuracy.\r\n",
        "    '''\r\n",
        "    accuracy=[]\r\n",
        "    for i in range(len(predection)):      \r\n",
        "        accuracy.append(predection[i]==label[i])\r\n",
        "    return sum(accuracy)/len(predection)    \r\n",
        "\r\n",
        "  def all_evaluation(self, predection, label):\r\n",
        "    '''\r\n",
        "    Single entry point to calculate the metric required by the evaluation_type attribute.\r\n",
        "    Arguments:\r\n",
        "      prediction: Array of model predections.\r\n",
        "      label: Array of true labels.\r\n",
        "    Returns: \r\n",
        "      The metric required by the evaluation_type attribute. If evaluation_type is not specified, it returns all available evaluation metrics.\r\n",
        "    '''\r\n",
        "\r\n",
        "    if (self.evaluation_type==\"accuracy\"):\r\n",
        "      return self.accuracy (predection,label)\r\n",
        "\r\n",
        "    elif (self.evaluation_type==\"recall\"):\r\n",
        "      _,recall,_=self.calculate_matrix(predection ,label)\r\n",
        "      return recall\r\n",
        "\r\n",
        "    elif (self.evaluation_type==\"precision\"):\r\n",
        "      precision,_,_=self.calculate_matrix(predection ,label)\r\n",
        "      return precision\r\n",
        "\r\n",
        "    elif (self.evaluation_type==\"f1\"):\r\n",
        "      _,_,F1=self.calculate_matrix(predection ,label)\r\n",
        "      return F1\r\n",
        "\r\n",
        "    elif (self.evaluation_type==\"confusion matrix\"):\r\n",
        "      self.confusion_matrix(predection ,label)\r\n",
        "\r\n",
        "\r\n",
        "    else:\r\n",
        "      if self.plot==1:\r\n",
        "        self.confusion_matrix(predection ,label)\r\n",
        "\r\n",
        "      precision,recall,f1=self.calculate_matrix(predection ,label)\r\n",
        "      return  precision,recall,f1,self.accuracy (predection,label)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDy03iqeCWUY"
      },
      "source": [
        "class Activation:\r\n",
        "    '''\r\n",
        "    This class encapsulates the following activation functions: ReLU, sigmoid, tanh.\r\n",
        "    This class aims to apply one activation function to a given input. \r\n",
        "    The class contains one attribute that determines which activation function is applied to the input given to the ActivationFn method.  \r\n",
        "    The class is meant to be accessed through the following functions: init, ActivationFn and DerivativeFn.\r\n",
        "    '''\r\n",
        "    def __init__(self, activation=\"relu\"):\r\n",
        "        '''\r\n",
        "        The __init__ function is called whenever the class is instantiated. \r\n",
        "        Arguments:\r\n",
        "            activation: String represents the activation function that the instance object will be representing.\r\n",
        "        '''\r\n",
        "        self.activation=activation\r\n",
        "\r\n",
        "    def sigmoid(self, z):\r\n",
        "        '''\r\n",
        "        Computes the sigmoid of the input z (array of predictions).\r\n",
        "        '''\r\n",
        "        s = 1/(1+np.exp(-z))     \r\n",
        "        return s\r\n",
        "\r\n",
        "    def tanh(self, z):\r\n",
        "        '''\r\n",
        "        Computes the tanh of the input z (array of predictions).\r\n",
        "        '''\r\n",
        "        s = (np.exp(z)-np.exp(-z))/(np.exp(z)+np.exp(-z))    \r\n",
        "        return s\r\n",
        "        \r\n",
        "    def relu(self, x):\r\n",
        "        '''\r\n",
        "        Computes the max of the input x (array of predictions) and zero. This max is technically the ReLU.\r\n",
        "        '''\r\n",
        "        s = np.maximum(0,x)    \r\n",
        "        return s\r\n",
        "\r\n",
        "    def sigmoid_derivative(self, x):\r\n",
        "        '''\r\n",
        "        Computes the derivative of the sigmoid with respect to the input x (array of predictions).\r\n",
        "        '''\r\n",
        "        s = self.sigmoid(x)\r\n",
        "        ds = s*(1-s)\r\n",
        "        return ds\r\n",
        "\r\n",
        "    def tanh_derivative(self, x):\r\n",
        "        '''\r\n",
        "        Computes the derivative of the tanh with respect to the input x (array of predictions).\r\n",
        "        '''\r\n",
        "        t = self.tanh(x)\r\n",
        "        dt = 1-np.power(t, 2)\r\n",
        "        return dt\r\n",
        "\r\n",
        "    def relu_derivative(self, x):\r\n",
        "        '''\r\n",
        "        Computes the derivative of the ReLU with respect to the input x (array of predictions).\r\n",
        "        '''\r\n",
        "        return x>0     \r\n",
        "\r\n",
        "    def softmax(self, x):\r\n",
        "        '''\r\n",
        "        Computes the softmax of the input x (array of predictions).\r\n",
        "        '''\r\n",
        "        exps=np.exp(x)\r\n",
        "        return exps/np.sum(exps)\r\n",
        "\r\n",
        "    def DerivativeFn(self, x):\r\n",
        "        '''\r\n",
        "        Computes the derivative of the activation function with respect to the input (array of predictions). This function is meant to be the entry point when computing the derivative i.e. don't call the specific derivative functions.\r\n",
        "        '''\r\n",
        "        if self.activation==\"relu\":\r\n",
        "            return self.relu_derivative(x)\r\n",
        "        elif self.activation==\"tanh\":\r\n",
        "            return self.tanh_derivative(x)    \r\n",
        "        elif self.activation==\"sigmoid\":\r\n",
        "            return self.sigmoid_derivative(x)\r\n",
        "        # elif self.activation==\"softmax\":\r\n",
        "        #     return self.softmax_derivative(x)\r\n",
        "            \r\n",
        "    def ActivationFn(self, x):\r\n",
        "        '''\r\n",
        "        Computes the activation function with respect to the input (array of predictions). This function is meant to be the entry point when computing the activation i.e. don't call the specific activation functions.\r\n",
        "        '''\r\n",
        "        if self.activation==\"relu\":\r\n",
        "            return self.relu(x)\r\n",
        "        elif self.activation==\"tanh\":\r\n",
        "            return np.tanh(x)    \r\n",
        "        elif self.activation==\"sigmoid\":\r\n",
        "            return self.sigmoid(x)\r\n",
        "        elif self.activation==\"softmax\":\r\n",
        "            return self.softmax(x) "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WEkBl2759wK"
      },
      "source": [
        "class Loss:\r\n",
        "  '''\r\n",
        "  Class encapsulates the following loss functions: Categorical Crossentropy and Mean Squared Error.\r\n",
        "  The class is meant to be used via the functions: loss, delta_loss.\r\n",
        "  Attributes:\r\n",
        "    loss_type: String indicates the type of the loss function required.\r\n",
        "  '''\r\n",
        "  def __init__(self,loss_type=\"categorical_crossentropy\"):\r\n",
        "    '''\r\n",
        "    Sets the attributes.\r\n",
        "    '''\r\n",
        "    self.loss_type=loss_type\r\n",
        "    #built-in functions\r\n",
        "      #Probabilistic losses\r\n",
        "      #1           \r\n",
        "  def categorical_crossentropy (self, predection, label):\r\n",
        "    '''\r\n",
        "    Calculates the categorical crossentropy loss of a given set of predictions of certain learning process.\r\n",
        "    Arguments:\r\n",
        "      predection: Array of predictions.\r\n",
        "      label: Array of labels.\r\n",
        "    Returns:\r\n",
        "      float representing the categorical crossentropy (log) loss. \r\n",
        "    '''\r\n",
        "    sum=0\r\n",
        "\r\n",
        "    for i in range(len(predection)):\r\n",
        "      sum=sum-np.log(predection[i][label[i]])    \r\n",
        "    return sum\r\n",
        "    \r\n",
        "  def delta_categorical_crossentropy(self, pred, label):\r\n",
        "    '''\r\n",
        "    Calculates the derivative of the categorical crossentropy loss with respect to its inputs.\r\n",
        "    Arguments:\r\n",
        "      predection: Array of predictions.\r\n",
        "      label: Array of labels.\r\n",
        "    Returns:\r\n",
        "      Array representing the derivative of the categorical crossentropy (log) loss with respect to every (scaler) input\r\n",
        "    '''\r\n",
        "    delta=np.array(pred)\r\n",
        "    delta[label]=-(1 - pred[label] )\r\n",
        "    return delta \r\n",
        "  #Regression losses\r\n",
        "  #1\r\n",
        "  def MeanSquaredError(self, predection, label):\r\n",
        "    '''\r\n",
        "    Calculates the MSE loss of a given set of predictions of certain learning process.\r\n",
        "    Arguments:\r\n",
        "      predection: Array of predictions.\r\n",
        "      label: Array of labels.\r\n",
        "    Returns:\r\n",
        "      float representing the MSE loss. \r\n",
        "    '''\r\n",
        "    error = 0.5*np.mean(np.square(label- predection), axis=-1)\r\n",
        "    return error \r\n",
        "  def delta_MeanSquaredError(self,predection, label):\r\n",
        "    '''\r\n",
        "    Calculates the derivative of the MSE loss with respect to its inputs.\r\n",
        "    Arguments:\r\n",
        "      predection: Array of predictions.\r\n",
        "      label: Array of labels.\r\n",
        "    Returns:\r\n",
        "      Array representing the derivative of the MSE with respect to every (scaler) input\r\n",
        "    '''\r\n",
        "    delta=np.mean((label - predection), axis=-1)\r\n",
        "    return delta\r\n",
        "  \r\n",
        "  def loss(self, predection, label):\r\n",
        "    '''\r\n",
        "    Single entry point to calculate the loss according to the attribute loos_type.\r\n",
        "    Arguments:\r\n",
        "      predection: Array of predictions.\r\n",
        "      label: Array of labels.\r\n",
        "    Returns:\r\n",
        "      float representing the required loss. \r\n",
        "    '''\r\n",
        "    if self.loss_type == \"categorical_crossentropy\":\r\n",
        "      return self.categorical_crossentropy (predection, label)\r\n",
        "    elif self.loss_type == \"MeanSquaredError\":\r\n",
        "      return self.MeanSquaredError(predection, label)\r\n",
        "\r\n",
        "  def delta_loss(self, predection, label):\r\n",
        "    '''\r\n",
        "    Single entry point to calculate the derivative of the loss with respect to its inputs according to the attribute loos_type.\r\n",
        "    Arguments:\r\n",
        "      predection: Array of predictions.\r\n",
        "      label: Array of labels.\r\n",
        "    Returns:\r\n",
        "      Array representing the derivative of the loss with respect to every (scaler) input.\r\n",
        "    '''\r\n",
        "    if self.loss_type == \"categorical_crossentropy\":\r\n",
        "      return self.delta_categorical_crossentropy (predection, label)\r\n",
        "    elif self.loss_type == \"MeanSquaredError\":\r\n",
        "      return self.delta_MeanSquaredError(predection, label)\r\n",
        "  \r\n",
        "      "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8AqyeJNydRD"
      },
      "source": [
        "class Layer:\r\n",
        "    '''\r\n",
        "    Abstract class representing the following layers: Conv, Dense, Pool\r\n",
        "    Classes that inherits from this class have to implement the forward and backward methods to specify how the calculations goes on the forward path and the backward path.\r\n",
        "    '''\r\n",
        "    def __init__(self):\r\n",
        "        self.input = None\r\n",
        "        self.output = None\r\n",
        "\r\n",
        "    # computes the output Y of a layer for a given input X\r\n",
        "    def forward(self, input):\r\n",
        "        raise NotImplementedError\r\n",
        "\r\n",
        "    # computes dE/dX for a given dE/dY (and update parameters if any)\r\n",
        "    def backward(self, output_error, learning_rate):\r\n",
        "        raise NotImplementedError"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5KqhqhwyeJx"
      },
      "source": [
        "class Dense(Layer):\r\n",
        "    '''\r\n",
        "    Class that encapsulates how the fully connected (Dense) layer works.\r\n",
        "    It simply performs a learnt affine transformation.\r\n",
        "    Attributes:\r\n",
        "        activation: String represents the type of activation function used at the instance of the Dense layer.\r\n",
        "        learning_rate: float represents the learning rate.\r\n",
        "        weights: Matrix of layer weights of size (output_units, input_units).\r\n",
        "        biases: Array of layer biases.\r\n",
        "        D: Array of learnt predictions before applying any activation function.\r\n",
        "        activationObject: Object of type activation represents the activation function defined by the activation attribute.\r\n",
        "    '''\r\n",
        "    def __init__(self, input_units, output_units, activation=\"relu\", learning_rate=0.01):\r\n",
        "        '''\r\n",
        "        Sets the attributes and initializes weights (Xavier initialization) and biases (zeros)\r\n",
        "        Arguments:\r\n",
        "            input_units: Integer represents number of hidden units in the previous layer.\r\n",
        "            output_units: Integer represents number of hidden units in the current layer.\r\n",
        "            activation: String represents type of activation function to be used in this layer.\r\n",
        "            learning_rate: float representing the learning rate.\r\n",
        "        '''\r\n",
        "        # A dense layer is a layer which performs a learned affine transformation:\r\n",
        "        # f(x) = <W*x> + b\r\n",
        "        self.activation=activation\r\n",
        "        self.learning_rate = learning_rate\r\n",
        "        self.weights = np.random.normal(loc=0.0, \r\n",
        "                                        scale = np.sqrt(2/(input_units+output_units)), \r\n",
        "                                        size = (input_units,output_units))\r\n",
        "        \r\n",
        "        self.biases = np.zeros(output_units)\r\n",
        "        self.D=1\r\n",
        "        self.activationObject=Activation(activation)\r\n",
        "\r\n",
        "    def forward(self, input):\r\n",
        "        '''\r\n",
        "        Does the affine transformation on the inputs and applies the activation function on the output of the transformation.\r\n",
        "        Arguments:\r\n",
        "            input: Array of inputs.\r\n",
        "        Returns:\r\n",
        "            The output of the chosen activation function after applying it to the result of the affine transformation.\r\n",
        "        '''\r\n",
        "        self.D=np.dot(input,self.weights) + self.biases\r\n",
        "        return self.activationObject.ActivationFn(self.D)\r\n",
        "\r\n",
        "    def backward(self, grad_output, input):\r\n",
        "        '''\r\n",
        "        Calculates the gradient of the output of the layer with respect to its input and updates the weights and biases after calculating the gradient of the output with respect to the weights and biases.\r\n",
        "        Arguments:\r\n",
        "            grad_output: Array represents the gradient of the previous stage (according to the reversed computation graph) input with respect to the current layer output.\r\n",
        "            input: Array of inputs to the layer (same as the input to forward fn).\r\n",
        "        Returns: \r\n",
        "            grad_input: Array represents the gradient of the previous stage (according to the reversed computation graph) input with respect to the current layer input.\r\n",
        "        '''\r\n",
        "        # compute d f / d x = d f / d dense * d dense / d x\r\n",
        "\r\n",
        "        # where d dense/ d x = weights transposed\r\n",
        "        if self.activation!=\"softmax\":\r\n",
        "          grad_output=np.multiply(grad_output,self.activationObject.DerivativeFn(self.D))  \r\n",
        "        grad_input = np.dot(self.weights,grad_output)\r\n",
        "        \r\n",
        "        # compute gradient w.r.t. weights and biases\r\n",
        "        grad_weights=np.zeros((len(grad_output),len(input)))\r\n",
        "        ip=input.reshape((input.size,1))\r\n",
        "        gop=grad_output.reshape((grad_output.size,1))\r\n",
        "        grad_weights=np.dot(ip,gop.T)      \r\n",
        "        grad_biases = grad_output\r\n",
        "\r\n",
        "        assert grad_weights.shape == self.weights.shape and grad_biases.shape == self.biases.shape\r\n",
        "\r\n",
        "        self.weights = self.weights - self.learning_rate * grad_weights\r\n",
        "        self.biases = self.biases - self.learning_rate * grad_biases\r\n",
        "\r\n",
        "        return grad_input\r\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0U6yJp_4p04"
      },
      "source": [
        "\r\n",
        "class Conv():\r\n",
        "    '''\r\n",
        "    Class encapsulats the working of the convolution layer.\r\n",
        "    Attributes:\r\n",
        "        n_C: Integer represents the number of filters in the current convolutional layer.\r\n",
        "        W: Matrix represents the weights of the filters in the current convolutional layer.\r\n",
        "        b: Array represents the biases corresponding to the current convolutional layer filters (Every filter has its own bias).\r\n",
        "        stride: Integer represents the strides (steps of the filter).\r\n",
        "        padding: String represents the type of padding (same or valid). \r\n",
        "        learning_rate: float represents the learning rate.\r\n",
        "        f: Integer represents the filter (kernel) size.\r\n",
        "        n_C_prev: Integer represents the number of filters in the previous convolutional layer.\r\n",
        "        activation: String represents the required activation function.\r\n",
        "        pad: Integer represents number of values padded to one edge of the input.\r\n",
        "        D: float represents the result of the convolution operation before applying the activation function.\r\n",
        "        activationObject: Object of type activation represents the activation function defined by the activation attribute.\r\n",
        "    '''\r\n",
        "    def __init__(self, filters=256, n_prev=3, kernel_size=11, strides=1, padding=\"valid\", activation=\"tanh\", learning_rate=0.0001):\r\n",
        "        '''\r\n",
        "        Sets the attributes and initializes weights (random normal initialization) and biases (zeros)\r\n",
        "        '''\r\n",
        "        self.n_C=filters\r\n",
        "        self.W = np.random.normal(loc=0.0,scale=1,size=(kernel_size,kernel_size,n_prev,filters))\r\n",
        "        self.b=np.zeros(shape=(1,filters))\r\n",
        "        self.stride=strides\r\n",
        "        self.learning_rate=learning_rate\r\n",
        "        self.padding=padding\r\n",
        "        self.f=kernel_size\r\n",
        "        self.n_C_prev=n_prev\r\n",
        "        self.activation=activation\r\n",
        "        self.pad=0\r\n",
        "        self.D=1\r\n",
        "        self.activationObject=Activation(activation)\r\n",
        " \r\n",
        "    def conv_single_step(self, a_slice_prev, W, b):\r\n",
        "        '''\r\n",
        "        Does a single convolution step, which is multiplying the kernel weights by the window of the input of the same size of the kernel and adding a bias vector.\r\n",
        "        Arguments:\r\n",
        "            a_slice_prev: Matrix representing a window of the input of the same size of the kernel.\r\n",
        "            W: Matrix of kernel weights.\r\n",
        "            b: Vector of kernel biases.\r\n",
        "        Returns:\r\n",
        "            Sum of kernel weights multiplied by the elements of the window and the biases.\r\n",
        "        '''\r\n",
        "        s = np.multiply(a_slice_prev, W) + b\r\n",
        "        Z = np.sum(s)\r\n",
        "        return Z\r\n",
        "\r\n",
        "    def zero_pad(self, X):\r\n",
        "        '''\r\n",
        "        Pads an input matrix with zeros.\r\n",
        "        Arguments:\r\n",
        "            X: The input matrix to be padded.\r\n",
        "        Returns:\r\n",
        "            X_pad: The input matrix after padding it with zeros.\r\n",
        "        '''\r\n",
        "        X_pad = np.pad(X, ((self.pad, self.pad), (self.pad, self.pad), (0, 0)), 'constant', constant_values=0)\r\n",
        "        return X_pad\r\n",
        " \r\n",
        "    def forward(self, A_prev):\r\n",
        "        '''\r\n",
        "        Does the convolution operation on the whole input.\r\n",
        "        Arguments:\r\n",
        "            A_prev: The input matrix to be convolved with the kernels.\r\n",
        "        Returns:\r\n",
        "            A: The result of convolving A_prev with the kernels with the padding and strides being taken into consideration.\r\n",
        "        '''\r\n",
        "\r\n",
        "        ( n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\r\n",
        "        \r\n",
        "        if self.padding==\"valid\":\r\n",
        "          self.pad=0\r\n",
        "        else:\r\n",
        "          self.pad=int((n_H_prev*(self.stride-1)+self.f-self.stride)/2)\r\n",
        "        \r\n",
        "        n_H = int((n_H_prev - self.f + 2 * self.pad) / self.stride) + 1\r\n",
        "        n_W = int((n_W_prev - self.f + 2 * self.pad) / self.stride) + 1\r\n",
        "        \r\n",
        "        Z = np.zeros((n_H, n_W, self.n_C))\r\n",
        "        A_prev_pad = np.pad(A_prev,((self.pad,self.pad),(self.pad,self.pad),(0,0)), 'constant', constant_values = (0,0))\r\n",
        "        a_prev_pad = A_prev_pad  \r\n",
        "        for h in range(n_H):                           # loop over vertical axis of the output volume\r\n",
        "            for w in range(n_W):                       # loop over horizontal axis of the output volume\r\n",
        "                for c in range(self.n_C):                   # loop over channels (= #filters) of the output volume\r\n",
        "                    # Find the corners of the current \"slice\" \r\n",
        "                    vert_start = h * self.stride\r\n",
        "                    vert_end = vert_start + self.f\r\n",
        "                    horiz_start = w * self.stride\r\n",
        "                    horiz_end = horiz_start + self.f\r\n",
        "                    # Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). \r\n",
        "                    a_slice_prev = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\r\n",
        "                    # Convolve the (3D)11 slice with the correct filter W and bias b, to get back one output neuron.\r\n",
        "                    Z[ h, w, c] = self.conv_single_step(a_slice_prev, self.W[:,:,:,c], self.b[:,c])\r\n",
        "        # Making sure your output shape is correct\r\n",
        "        assert(Z.shape == (n_H, n_W, self.n_C))  \r\n",
        "        # Save information in \"cache\" for the backprop\r\n",
        "        self.D=Z\r\n",
        "        A=self.activationObject.ActivationFn(Z)   \r\n",
        "        return A\r\n",
        "\r\n",
        "    def backward(self, dA, A_prev):\r\n",
        "        '''\r\n",
        "        Calculates the derivative of the output of the current convolution layer with respect to the input and updates the kernel weights and biases by calculating the derivative of the output with respect to the kernel weights and biases.\r\n",
        "        Arguments:\r\n",
        "            dA: The derivative of the output of the previous convolution layer (according to the reverse computational graph) with respect to the input of the current convolutional layer (according to the reverse computional graph).\r\n",
        "            A_prev: Matrix of inputs to the current convolutional layer.  \r\n",
        "        Returns:\r\n",
        "            dA_prev: The derivative of the output of the current convolution layer with respect to the input\r\n",
        "        '''\r\n",
        " \r\n",
        "        dZ=np.multiply(dA,self.activationObject.DerivativeFn(self.D))\r\n",
        "        (n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\r\n",
        "        ( n_H, n_W, n_C) = dZ.shape\r\n",
        "        \r\n",
        "        # Initialize dA_prev, dW, db with the correct shapes\r\n",
        "        dA_prev = np.zeros((n_H_prev, n_W_prev, n_C_prev))                 \r\n",
        "        dW = np.zeros((self.f, self.f, n_C_prev, n_C))\r\n",
        "        db = np.zeros(( 1, n_C))\r\n",
        " \r\n",
        "        # Pad A_prev and dA_prev\r\n",
        "        #if self.padding==\"valid\":\r\n",
        "        A_prev_pad = self.zero_pad(A_prev)\r\n",
        "        dA_prev_pad = self.zero_pad(dA_prev)\r\n",
        "        \r\n",
        "        # select ith training example from A_prev_pad and dA_prev_pad\r\n",
        "        a_prev_pad = A_prev_pad\r\n",
        "        da_prev_pad = dA_prev_pad\r\n",
        "\r\n",
        "        for h in range(n_H):                   # loop over vertical axis of the output volume\r\n",
        "            for w in range(n_W):               # loop over horizontal axis of the output volume\r\n",
        "                for c in range(n_C):           # loop over the channels of the output volume\r\n",
        "                    \r\n",
        "                    # Find the corners of the current \"slice\"\r\n",
        "                    vert_start = h * self.stride\r\n",
        " \r\n",
        "                    vert_end = vert_start + self.f\r\n",
        "                    horiz_start = w * self.stride\r\n",
        " \r\n",
        "                    horiz_end = horiz_start + self.f\r\n",
        "                    \r\n",
        "                    # Use the corners to define the slice from a_prev_pad\r\n",
        "                    a_slice = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\r\n",
        "                    # Update gradients for the window and the filter's parameters \r\n",
        "                    da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += self.W[:,:,:,c] * dZ[h, w, c]\r\n",
        "                    #update each filter c with the gradient in the index h and w of the dZ as each filter parameter is now affected by the gradient of each element gradient in Z \r\n",
        "                    dW[:,:,:,c] += a_slice * dZ[h, w, c]\r\n",
        "                    db[:,c] += dZ[h, w, c]\r\n",
        "                    \r\n",
        "        if self.padding==\"valid\":\r\n",
        "           dA_prev=da_prev_pad\r\n",
        "        else:\r\n",
        "           dA_prev=da_prev_pad[self.pad:-self.pad, self.pad:-self.pad, :]\r\n",
        "\r\n",
        "        assert(dA_prev.shape == (n_H_prev, n_W_prev, n_C_prev))\r\n",
        "\r\n",
        "        self.W=self.W-self.learning_rate*dW\r\n",
        "        self.b=self.b-self.learning_rate*db\r\n",
        "        return dA_prev\r\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32hBPeTp7Zj-"
      },
      "source": [
        "class Pool(Layer):\r\n",
        "    '''\r\n",
        "    Class encapsulates the pooling process.\r\n",
        "    Attributes:\r\n",
        "        f: Integer represents the kernel size.\r\n",
        "        n_prev: Integer represents the number of filters in the previous layer.\r\n",
        "        stride: Integer represents the strides (steps of the filter).\r\n",
        "        padding: String represents the type of padding (same or valid).\r\n",
        "        pad: Integer represents number of values padded to one edge of the input.\r\n",
        "        mode: String represents the mode of Pooling (max or average).\r\n",
        "    '''\r\n",
        "    def __init__(self, pool_size=2, n_prev=3, strides=2, padding=\"valid\", mode = \"max\"):\r\n",
        "        '''\r\n",
        "        Sets the attributes.\r\n",
        "        '''\r\n",
        "        self.f=pool_size\r\n",
        "        self.n_prev=n_prev\r\n",
        "        self.stride=strides\r\n",
        "        self.padding=padding\r\n",
        "        self.pad=0\r\n",
        "        self.mode=mode\r\n",
        "\r\n",
        "    def forward(self, A_prev):\r\n",
        "        '''\r\n",
        "        Does the pooling operation on the whole input i.e. taking the max or average of some window of the input and repeating for the whole input. \r\n",
        "        Arguments:\r\n",
        "            A_prev: The input matrix to be pooled.\r\n",
        "        Returns:\r\n",
        "            A: The result of applying the pooling on the whole with the padding and strides being taken into consideration.\r\n",
        "        '''\r\n",
        "        (n_H_prev, n_W_prev, n_C_prev) = A_prev.shape \r\n",
        "        # Define the dimensions of the output\r\n",
        "\r\n",
        "        if self.padding==\"valid\":\r\n",
        "            self.pad=0\r\n",
        "        else:\r\n",
        "            self.pad=int((n_H_prev*(self.stride-1)+self.f-self.stride)/2)\r\n",
        "\r\n",
        "        n_H = int(1 + (n_H_prev - self.f) / self.stride)\r\n",
        "        n_W = int(1 + (n_W_prev - self.f) / self.stride)\r\n",
        "        n_C = n_C_prev\r\n",
        "\r\n",
        "        # Initialize output matrix A\r\n",
        "        A = np.zeros((n_H, n_W,n_C))              \r\n",
        "        for h in range(n_H):                     # loop on the vertical axis of the output volume\r\n",
        "            for w in range(n_W):                 # loop on the horizontal axis of the output volume\r\n",
        "                for c in range (n_C):            # loop over the channels of the output volume\r\n",
        "                    \r\n",
        "                    # Find the corners of the current \"slice\" (4 lines)\r\n",
        "                    vert_start = h * self.stride\r\n",
        "                    vert_end = vert_start + self.f\r\n",
        "                    horiz_start = w * self.stride\r\n",
        "                    horiz_end = horiz_start + self.f\r\n",
        "                    \r\n",
        "                    # Use the corners to define the current slice on the ith training example of A_prev, channel c. (1 line)\r\n",
        "                    a_prev_slice = A_prev[vert_start:vert_end, horiz_start:horiz_end, c]\r\n",
        "                    # Compute the pooling operation on the slice. Use an if statment to differentiate the modes. Use np.max/np.mean.\r\n",
        "\r\n",
        "                    if self.mode == \"max\":\r\n",
        "                        A[h, w, c] = np.max(a_prev_slice)\r\n",
        "                    elif self.mode == \"average\":\r\n",
        "                        A[h, w, c] = np.mean(a_prev_slice)\r\n",
        "\r\n",
        "        # Making sure your output shape is correct\r\n",
        "        assert(A.shape == (n_H, n_W, n_C))\r\n",
        "\r\n",
        "        return A\r\n",
        "\r\n",
        "    def create_mask_from_window(self, x):\r\n",
        "        '''\r\n",
        "        Creates a mask of zeros everywhere except for the index at which the maximum occurs. (To be used in back probagation through the pooling layer)\r\n",
        "        Arguments:\r\n",
        "            x: Array to get the mask based on it.\r\n",
        "        Returns:\r\n",
        "            mask: Mask of one at the maximum and zero everywhere.\r\n",
        "        '''\r\n",
        "\r\n",
        "        mask = x == np.max(x) \r\n",
        "        return mask\r\n",
        "\r\n",
        "    def distribute_value(self, dz, shape):\r\n",
        "        '''\r\n",
        "        Constructs a matrix of averages to be distributed across a window of the input matrix.\r\n",
        "        Arguments:\r\n",
        "            dz: The matrix that its values needes to be divided by the kernel size to affect the upcoming matrix correctly.\r\n",
        "            shape: Tuple of integers represents the size of the average pooling kernel.\r\n",
        "        Returns:\r\n",
        "            a: A matrix where every entry is the average value \r\n",
        "        '''\r\n",
        "        (n_H, n_W) = shape\r\n",
        "        # Compute the value to distribute on the matrix\r\n",
        "        average = dz / (n_H * n_W)       \r\n",
        "        a = np.ones(shape) * average   \r\n",
        "        return a\r\n",
        "\r\n",
        "    def backward(self, dA, A_prev):\r\n",
        "        '''\r\n",
        "        Backpropagates through the pooling layer i.e. calculate the gradients of the output of current the pooling layer with respect to the inputs of the current pooling layer.\r\n",
        "        Arguments:\r\n",
        "            dA: The derivative of the output of the previous layer (according to the reverse computational graph) with respect to the input of the current layer (according to the reverse computional graph).\r\n",
        "            A_prev: Matrix of inputs to the current pooling layer.  \r\n",
        "        Returns:\r\n",
        "            dA_prev: The derivative of the output of the current pooling layer with respect to the input\r\n",
        "        '''\r\n",
        "\r\n",
        "        n_H_prev, n_W_prev, n_C_prev = A_prev.shape\r\n",
        "        n_H, n_W, n_C = dA.shape\r\n",
        "        # Initialize dA_prev with zeros \r\n",
        "        dA_prev = np.zeros(A_prev.shape)\r\n",
        "        # select training example from A_prev\r\n",
        "        a_prev = A_prev\r\n",
        "        for h in range(n_H):                   # loop on the vertical axis\r\n",
        "            for w in range(n_W):               # loop on the horizontal axis\r\n",
        "                for c in range(n_C):           # loop over the channels (depth)\r\n",
        "                    # Find the corners of the current \"slice\" \r\n",
        "                    vert_start = h\r\n",
        "                    vert_end = vert_start + self.f\r\n",
        "                    horiz_start = w\r\n",
        "                    horiz_end = horiz_start + self.f\r\n",
        "  \r\n",
        "                    # Compute the backward propagation in both modes.\r\n",
        "                    if self.mode == \"max\":\r\n",
        "                        # Use the corners and \"c\" to define the current slice from a_prev \r\n",
        "                        a_prev_slice = a_prev[vert_start:vert_end, horiz_start:horiz_end, c]\r\n",
        "                        # Create the mask from a_prev_slice \r\n",
        "                        mask = self.create_mask_from_window(a_prev_slice)\r\n",
        "                        # Set dA_prev to be dA_prev + (the mask multiplied by the correct entry of dA) \r\n",
        "                        #update the element with the max value\r\n",
        "                        dA_prev[ vert_start:vert_end, horiz_start:horiz_end, c] += np.multiply(mask, dA[ h, w, c])\r\n",
        "                        \r\n",
        "                    elif self.mode == \"average\":\r\n",
        "                        # Get the value a from dA \r\n",
        "                        da = dA[h, w, c]\r\n",
        "                        # Define the shape of the filter as fxf \r\n",
        "                        shape = (self.f,self.f)\r\n",
        "                        # Distribute it to get the correct slice of dA_prev. i.e. Add the distributed value of da. \r\n",
        "                        dA_prev[vert_start:vert_end, horiz_start:horiz_end, c] += self.distribute_value(da, shape)\r\n",
        "        \r\n",
        "        assert(dA_prev.shape == A_prev.shape)\r\n",
        "        \r\n",
        "        return dA_prev       "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OezkRK6v2Iz"
      },
      "source": [
        "class model():\n",
        "    '''\n",
        "    Class encapsulates the model with its layers.\n",
        "    Attributes:\n",
        "      layers: List of objects that inherits from the Layer class. \n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "        '''\n",
        "        Initializes the layers attribute to an empty list.\n",
        "        '''\n",
        "        self.layers = []\n",
        "        \n",
        "\n",
        "    def normalization(self, Arr):\n",
        "      '''\n",
        "      Normalizes (subtracts the mean and divides by the standard deviation) some input array.\n",
        "      Arguments:\n",
        "        Arr: Input array to be normalized.\n",
        "      Returns:\n",
        "        Normalized array of inputs.\n",
        "      '''\n",
        "      epsilon=0.0000001\n",
        "      arr=0 \n",
        "      arr = Arr - Arr.mean(axis=0)\n",
        "      arr = arr / (np.abs(arr).max(axis=0)+epsilon)\n",
        "      return arr\n",
        "\n",
        "    def add(self, Layer):\n",
        "      '''\n",
        "      Adds specific layer to the model\n",
        "      Arguments:\n",
        "        Layer: Some object inherits from Layer class (Conv, Dense or Pool) \n",
        "      '''\n",
        "      self.layers.append(Layer)  \n",
        "\n",
        "    def summary(self):\n",
        "      '''\n",
        "      Prints a table summerizes the main info of the model like: Layers, number of parameters, etc.\n",
        "      '''\n",
        "      sum=0\n",
        "      table = Texttable()\n",
        "      table.header([\"Layer\", \"filters size\", \"number of filters\", \"pad\", \"stride\", \"number of paramters\"])\n",
        "      for layer in self.layers:\n",
        "        if type(layer)==Conv:\n",
        "          F=layer.f\n",
        "          numLayers=layer.n_C\n",
        "          K=layer.n_C_prev\n",
        "          parameters=(F*F*K+1)*numLayers\n",
        "          sum+=parameters\n",
        "          table.add_row([\"Conv layer\", \"{}x{}\".format(F,F),numLayers ,layer.padding,layer.stride,parameters])\n",
        "        elif type(layer)==Dense:\n",
        "          sum+=layer.biases.size+layer.weights.size\n",
        "          table.add_row([\"Dense layer\",\"-\",\"-\" ,\"-\",\"-\",layer.biases.size+layer.weights.size])\n",
        "        elif type(layer)==Pool:\n",
        "          F=layer.f\n",
        "          table.add_row([\"Pool layer\", \"{}x{}\".format(F,F),\"-\" ,layer.padding,layer.stride,\"0\"])\n",
        "        else:\n",
        "          table.add_row([\"flatten layer\", \"-\",\"-\" ,\"-\",\"-\",\"0\"])\n",
        "      table.add_row([\"Total\", \"-\",\"-\" ,\"-\",\"-\",sum])\n",
        "      print(table.draw())\n",
        "\n",
        "    def evaluate(self, x_test, y_test, loss_type=\"categorical_crossentropy\", batchsize=1, metrics=\"accuracy\"):\n",
        "          '''\n",
        "          Performs the test phase and shows the confusion matrix.\n",
        "          Arguments: \n",
        "            x_test: The test inputs array.\n",
        "            y_test: The test labels array.\n",
        "            loss_type: String indicates the loss required to evaluate against.\n",
        "            batch_size: Integer indicates the number of examples forwarded as a batch.\n",
        "            metrics: String indicates the required evaluation metric.\n",
        "          '''\n",
        "          lossobj=Loss(loss_type)\n",
        "          evaluationobj=Evaluation_metrics(metrics,max(y_test), plot = 1)\n",
        "          output_layer=[]\n",
        "          forward_outputs=[]\n",
        "          test_predection=[]\n",
        "          flatten_shape=0\n",
        "          #samples=len(x_test)\n",
        "          samples=100\n",
        "          batches=int(samples/batchsize)\n",
        "          print(\"Testing is running----------------->\")\n",
        "          new_samples=len(x_test)\n",
        "          test_predection.clear()\n",
        "          forward_outputs.clear()\n",
        "          for j in range(batches):       \n",
        "            for b in range(batchsize):    \n",
        "              output_layer.clear()     \n",
        "              forward_input=0    \n",
        "              forward_input = x_test[j*batchsize+b]\n",
        "              data=forward_input\n",
        "              output_layer.append(data)\n",
        "              # forward propagation       \n",
        "              for layer in self.layers:\n",
        "                  if (layer==\"flatten\"):\n",
        "                    flatten_shape=forward_input.shape                      \n",
        "                    forward_input=forward_input.flatten()\n",
        "                    output_layer.append(forward_input)                                          \n",
        "                  else:    \n",
        "                    forward_input = layer.forward(forward_input)\n",
        "                    output_layer.append(forward_input) \n",
        "              forward_outputs.append(np.argmax(output_layer[-1]))\n",
        "              test_predection.append(output_layer[-1])     \n",
        "          \n",
        "          print(\"Loss ={}     \".format(lossobj.loss (test_predection, y_test[0:samples])))\n",
        "          if (metrics!=\"confusion matrix\"):\n",
        "            print(evaluationobj.all_evaluation(forward_outputs,y_test[0:samples]))\n",
        "          else :\n",
        "            evaluationobj.all_evaluation(forward_outputs,y_test[0:samples])  \n",
        "\n",
        "    def fit(self, x_train, y_train, loss_type=\"categorical_crossentropy\", epochs=0, validation_split=0.1, batchsize=1, plot=1, metrics=\"accuracy\"):\n",
        "        '''\n",
        "        Trains the model on the training set and validates against locally synthesized validation set.\n",
        "        Arguments:\n",
        "          x_train: The training inputs array.\n",
        "          y_train: The training labels array.\n",
        "          loss_type: String indicates the loss required to evaluate against.\n",
        "          epochs: Integer indicates the number of iterations on the whole training set\n",
        "          validation_split:float represents the ratio by which the mnist training files are split into validation and training sets. The validation_split equals the required portion of validation set of the total given training set.\n",
        "          batchsize: Integer indicates the number of training examples after which the learning parameters are updated\n",
        "          plot: If 1, the curves of loss and the required evaluation metrics versus epoch number are plotted.\n",
        "          metrics: String represents the required meteric to be plotted against the epoch number. If 'all', all evaluation metrics are plotted.\n",
        "        '''\n",
        "        lossobj=Loss(loss_type)\n",
        "        evaluationobj=Evaluation_metrics(metrics,max(y_train),plot)\n",
        "        Visualizerobj=Visualizer(metrics)\n",
        "        Visualizerobj_validate=Visualizer(metrics)\n",
        "\n",
        "        datalength = len(x_train)\n",
        "        splitor=int(datalength*validation_split)\n",
        "        x_validation = x_train[0:splitor]  #as i get the data randamly so i always get from the beggining to the disered length\n",
        "        y_validation = y_train[0:splitor]\n",
        "        x_train =      x_train[splitor:]\n",
        "        y_train =      y_train[splitor:]\n",
        "        state=np.random.get_state()\n",
        "        np.random.shuffle(x_validation)\n",
        "        np.random.set_state(state)\n",
        "        np.random.shuffle(y_validation)\n",
        "        output_layer=[]\n",
        "        output_batch_layer=[]\n",
        "        batch_grad=[]\n",
        "        forward_outputs=[]\n",
        "        validation_forward_outputs=[]\n",
        "        train_predection=[]\n",
        "        validation_predection=[]\n",
        "        flatten_shape=0\n",
        "        #samples= 200\n",
        "        #validation_samples=300\n",
        "        samples= len(x_train)\n",
        "        validation_samples=len(x_validation)\n",
        "        batches=int(samples/batchsize)\n",
        "        for i in range(epochs):\n",
        "\n",
        "            #shuffling\n",
        "            state=np.random.get_state()\n",
        "            np.random.shuffle(x_train)\n",
        "            np.random.set_state(state)\n",
        "            np.random.shuffle(y_train)\n",
        "\n",
        "            new_samples=len(x_train)\n",
        "            validation_grad=0\n",
        "            train_predection.clear()\n",
        "            validation_predection.clear()\n",
        "            validation_forward_outputs.clear()\n",
        "            forward_outputs.clear()\n",
        "  \n",
        "            for j in range(batches):\n",
        "\n",
        "              output_batch_layer.clear()\n",
        "              batch_grad.clear()\n",
        "\n",
        "              for b in range(batchsize):    \n",
        "\n",
        "                output_layer.clear()     \n",
        "                forward_input=0    \n",
        "                forward_input = x_train[j*batchsize+b]\n",
        "                data=forward_input\n",
        "                output_layer.append(data)\n",
        "                # forward propagation       \n",
        "\n",
        "                for layer in self.layers:\n",
        "\n",
        "                    if (layer==\"flatten\"):\n",
        "                      flatten_shape=forward_input.shape                      \n",
        "                      forward_input=forward_input.flatten()\n",
        "                      output_layer.append(forward_input)                                          \n",
        "                    else:    \n",
        "                      #if (type(layer) == Conv or Dense ):\n",
        "                        #norm=np.linalg.norm(forward_input)\n",
        "                        #forward_input=forward_input/(norm+0.00000001)\n",
        "                      forward_input = layer.forward(forward_input)\n",
        "                      output_layer.append(forward_input)\n",
        "                          \n",
        "                forward_outputs.append(np.argmax(output_layer[-1]))\n",
        "                train_predection.append(output_layer[-1])\n",
        "                grad=lossobj.delta_loss(output_layer[-1],y_train[j*batchsize+b])\n",
        "                output_batch_layer.append(output_layer)\n",
        "                batch_grad.append(grad)\n",
        "                #backward propagation  \n",
        "              reversed_layers= self.layers[::-1]\n",
        "              \n",
        "              for k in range(batchsize):\n",
        "                back=len(output_batch_layer[k])-2    \n",
        "                for rlayer in  reversed_layers: \n",
        "                    if (rlayer==\"flatten\"):\n",
        "                      backward_output=backward_output.reshape(flatten_shape)   \n",
        "                      batch_grad[k]=backward_output   \n",
        "                      back=back-1\n",
        "                    else:\n",
        "                      backward_output=rlayer.backward(batch_grad[k],output_batch_layer[k][back])\n",
        "                      batch_grad[k]=backward_output\n",
        "                      back=back-1\n",
        "\n",
        "            #print(\"validation is running----------------->\")\n",
        "            for l in range(validation_samples):  \n",
        "                validation_forward_input= x_validation[l]\n",
        "                for layer in self.layers:\n",
        "                  if (layer==\"flatten\"):            \n",
        "                      validation_forward_input=validation_forward_input.flatten()           \n",
        "                  else:\n",
        "                      validation_forward_input= layer.forward(validation_forward_input)       \n",
        "                validation_forward_outputs.append(np.argmax(validation_forward_input))\n",
        "                validation_predection.append(validation_forward_input)\n",
        "        \n",
        "\n",
        "            if plot:\n",
        "              if metrics==\"all\":\n",
        "                precision,recall,F1,accuracy=evaluationobj.all_evaluation(forward_outputs,y_train)  \n",
        "                log={    \n",
        "                    \"type\": \"train\",   \n",
        "                    \"loss\":lossobj.loss (train_predection, y_train),\n",
        "                    \"accuracy\" :accuracy,\n",
        "                    \"precision\":precision,\n",
        "                    \"f1\":F1,\n",
        "                    \"recall\":recall\n",
        "                }\n",
        "              else:\n",
        "                log={         \n",
        "                    \"type\": \"train\"  ,           \n",
        "                    \"loss\" : lossobj.loss (train_predection, y_train),\n",
        "                    metrics : evaluationobj.all_evaluation(forward_outputs,y_train)  \n",
        "                }           \n",
        "              if (metrics!=\"confusion matrix\"):\n",
        "                Visualizerobj.on_epoch_end(log)\n",
        "              else :\n",
        "                evaluationobj.all_evaluation(forward_outputs,y_train)  \n",
        "\n",
        "\n",
        "              if metrics==\"all\":\n",
        "                precision,recall,F1,accuracy=evaluationobj.all_evaluation(validation_forward_outputs,y_validation)  \n",
        "                log={ \n",
        "                    \"type\": \"test\" ,                               \n",
        "                    \"loss\":lossobj.loss (validation_predection, y_validation),\n",
        "                    \"accuracy\" :accuracy,\n",
        "                    \"precision\":precision,\n",
        "                    \"f1\":F1,\n",
        "                    \"recall\":recall\n",
        "                }\n",
        "              else:\n",
        "                log={   \n",
        "                    \"type\": \"test\" ,                            \n",
        "                    \"loss\" : lossobj.loss (validation_predection, y_validation),\n",
        "                    metrics : evaluationobj.all_evaluation(validation_forward_outputs,y_validation)  \n",
        "                }           \n",
        "              if (metrics!=\"confusion matrix\"):\n",
        "                Visualizerobj_validate.on_epoch_end(log)\n",
        "              else :\n",
        "                evaluationobj.all_evaluation(validation_forward_outputs,y_validation)  \n",
        "\n",
        "\n",
        "            else:\n",
        "              print(\"Epoch {}--------------------->\".format(i+1))\n",
        "              print(\"Training_Loss = {}\".format(lossobj.loss (train_predection, y_train)))\n",
        "              if (metrics!=\"confusion matrix\"):\n",
        "                if metrics==\"all\":\n",
        "                  p,r,f1,a=evaluationobj.all_evaluation(forward_outputs,y_train)\n",
        "                  print(\"Percision= {:.2f} ,Recall={:.2f},F1Score= {:.2f} ,Accuracy= {:.2f} \".format(p,r,f1,a))\n",
        "                else:\n",
        "                  print(\"{} = {:.2f}  \".format( metrics ,evaluationobj.all_evaluation(forward_outputs,y_train)))\n",
        "              else :\n",
        "                print(\"confusion matrix\")\n",
        "                evaluationobj.all_evaluation(forward_outputs,y_train)\n",
        "              print(\"==============================================================================================================\")\n",
        "              print(\"validation_loss = {}\".format( lossobj.loss (validation_predection, y_validation)))\n",
        "              if (metrics!=\"confusion matrix\"):\n",
        "                if metrics==\"all\":\n",
        "                  p,r,f1,a=evaluationobj.all_evaluation(validation_forward_outputs,y_validation)\n",
        "                  print(\"Percision= {:.2f} ,Recall={:.2f},F1Score= {:.2f} ,Accuracy= {:.2f} \".format(p,r,f1,a))\n",
        "                else:\n",
        "                  print(\"{} = {:.2f}  \".format( metrics ,evaluationobj.all_evaluation(validation_forward_outputs,y_validation)))\n",
        "              else :\n",
        "                print(\"confusion matrix\")\n",
        "                evaluationobj.all_evaluation(validation_forward_outputs,y_validation)\n",
        "              print(\"==============================================================================================================\")\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEuGI2RskiBp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "outputId": "1bb45d0f-c353-48eb-c086-91c89bc03460"
      },
      "source": [
        "#define data object\r\n",
        "mnist = Mnist('/')\r\n",
        "train_images, train_labels, test_images, test_labels = mnist.load()\r\n",
        "#normalization\r\n",
        "train_images = train_images / 255.0\r\n",
        "test_images = test_images / 255.0\r\n",
        "#reshape dataset 4D train/test features , 1D train/test labels \r\n",
        "train_images = train_images.reshape((60000,28,28,1))\r\n",
        "train_labels=train_labels.reshape((60000))\r\n",
        "test_images = test_images.reshape((10000,28,28,1))\r\n",
        "test_labels=test_labels.reshape((10000))\r\n",
        "#show sample of the dataset\r\n",
        "mnist.showSample(from_set= \"training\", startFrom= 0)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some files are missing. Do you want to download the dataset online? [y/n]y\n",
            "Downloading Training Images...\n",
            "Finished Successfully.\n",
            "Downloading Training Labels...\n",
            "Finished Successfully.\n",
            "Downloading Test Images...\n",
            "Finished Successfully.\n",
            "Downloading Test Labels...\n",
            "Finished Successfully.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 25 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4UPh-vhI_MS"
      },
      "source": [
        "#lenet5\r\n",
        "storage=Storage()\r\n",
        "#Instantiate an empty model\r\n",
        "model_test=model()\r\n",
        "# C1 Convolutional Layer\r\n",
        "model_test.add(Conv(filters=6,n_prev=1,kernel_size=5, strides=1, padding=\"same\",activation=\"tanh\"))\r\n",
        "# S2 Pooling Layer\r\n",
        "model_test.add(Pool(pool_size=2,n_prev=6, strides=2, padding=\"valid\", mode = \"average\"))\r\n",
        "# C3 Convolutional Layer\r\n",
        "model_test.add(Conv(filters=16,n_prev=6,kernel_size=5, strides=1, padding=\"valid\",activation=\"tanh\"))\r\n",
        "# S4 Pooling Layer\r\n",
        "model_test.add(Pool(pool_size=2,n_prev=16, strides=2, padding=\"valid\", mode = \"average\"))\r\n",
        "# C5 Convolutional Layer\r\n",
        "model_test.add(Conv(filters=120,n_prev=16,kernel_size=5, strides=1, padding=\"valid\",activation=\"tanh\"))\r\n",
        "#Flatten the CNN output so that we can connect it with fully connected layers\r\n",
        "model_test.add(\"flatten\")\r\n",
        "# FC6 Fully Connected Layer\r\n",
        "model_test.add(Dense(120,84, activation=\"tanh\"))\r\n",
        "#Output Layer with softmax activation\r\n",
        "model_test.add(Dense(84,10, activation=\"softmax\"))\r\n",
        "\r\n",
        "#Compile the model\r\n",
        "model_test.fit(train_images , train_labels,epochs=1,validation_split=0.1,batchsize=1,plot=1,metrics=\"all\")\r\n",
        "storage.save_model(model_test, \"buffer1\", \"/\")\r\n",
        "model_test.fit(train_images , train_labels,epochs=1,validation_split=0.1,batchsize=1,plot=1,metrics=\"all\")\r\n",
        "storage.save_model(model_test, \"buffer2\", \"/\")\r\n",
        "model_test.fit(train_images , train_labels,epochs=1,validation_split=0.1,batchsize=1,plot=1,metrics=\"all\")\r\n",
        "storage.save_model(model_test, \"buffer3\", \"/\")\r\n",
        "#show model summary\r\n",
        "model_test.summary()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVCnLFHars48",
        "outputId": "06c3aab2-a124-4fcd-e006-fb1d4e3f93e3"
      },
      "source": [
        "#test the trained model using the testing dataset\r\n",
        "model_test.evaluate(test_images , test_labels,metrics=\"accuracy\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing is running----------------->\n",
            "Loss =102.47156359658153     \n",
            "0.69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqETLJaUkvlJ"
      },
      "source": [
        "#define storage object to store the model\r\n",
        "storage=Storage()\r\n",
        "#save the model\r\n",
        "storage.save_model(model_test, \"buffer\", \"/\")\r\n",
        "modelX=storage.load_model(\"buffer\",\"/\")\r\n",
        "#modelX.evaluate(test_images , test_labels,metrics=\"accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8DCRBG5v4Yk"
      },
      "source": [
        "#alexnet\r\n",
        "#Instantiate an empty model\r\n",
        "model_test=model()\r\n",
        "# C1 Convolutional Layer\r\n",
        "model_test.add(Conv(filters=96,n_prev=1,kernel_size=11, strides=4, padding=\"valid\",activation=\"relu\"))\r\n",
        "# S2 Pooling Layer\r\n",
        "model_test.add(Pool(pool_size=3,n_prev=96, strides=2, padding=\"valid\", mode = \"max\"))\r\n",
        "# C3 Convolutional Layer\r\n",
        "model_test.add(Conv(filters=256,n_prev=96,kernel_size=5, strides=1, padding=\"same\",activation=\"relu\"))\r\n",
        "# S4 Pooling Layer\r\n",
        "model_test.add(Pool(pool_size=3,n_prev=256, strides=2, padding=\"valid\", mode = \"max\"))\r\n",
        "# C5 Convolutional Layer\r\n",
        "model_test.add(Conv(filters=384,n_prev=256,kernel_size=3, strides=1, padding=\"same\",activation=\"relu\"))\r\n",
        "# C6 Convolutional Layer\r\n",
        "model_test.add(Conv(filters=384,n_prev=384,kernel_size=3, strides=1, padding=\"same\",activation=\"relu\"))\r\n",
        "# C7 Convolutional Layer\r\n",
        "model_test.add(Conv(filters=256,n_prev=384,kernel_size=3, strides=1, padding=\"same\",activation=\"relu\"))\r\n",
        "# S8 Pooling Layer\r\n",
        "model_test.add(Pool(pool_size=3,n_prev=256, strides=2, padding=\"valid\", mode = \"max\"))\r\n",
        "#Flatten the CNN output so that we can connect it with fully connected layers\r\n",
        "model_test.add(\"flatten\")\r\n",
        "# FC8 Fully Connected Layer\r\n",
        "model_test.add(Dense(9216,4096, activation=\"relu\"))\r\n",
        "# FC9 Fully Connected Layer\r\n",
        "model_test.add(Dense(4096,1000, activation=\"relu\"))\r\n",
        "\r\n",
        "#Output Layer with softmax activation\r\n",
        "model_test.add(Dense(1000,10, activation=\"softmax\"))\r\n",
        "\r\n",
        "#Compile the model\r\n",
        "model_test.fit(train_images , train_labels,epochs=3,validation_split=0.1,batchsize=1,plot=1,metrics=\"all\")\r\n",
        "#show model summary\r\n",
        "model_test.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk51frVWlilR"
      },
      "source": [
        "model_test=model()\r\n",
        "#learning rate here is 0.01 for dense and conv accuracy about 84%\r\n",
        "model_test.add(Conv(filters=6,n_prev=1,kernel_size=5, strides=1, padding=\"same\",activation=\"tanh\"))\r\n",
        "model_test.add(Pool(pool_size=2,n_prev=6, strides=2, padding=\"valid\", mode = \"max\"))\r\n",
        "model_test.add(\"flatten\")\r\n",
        "model_test.add(Dense(1176,10, activation=\"softmax\"))\r\n",
        "\r\n",
        "train_images = train_images.reshape((60000,28,28,1))\r\n",
        "\r\n",
        "\r\n",
        "model_test.fit(train_images , train_labels,epochs=3,validation_split=0.1,batchsize=1,plot=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haM2EUyiBC6b"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqwEd6lF2EJp"
      },
      "source": [
        ""
      ]
    }
  ]
}